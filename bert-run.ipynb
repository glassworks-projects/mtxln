{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==2.11.0\n",
    "!pip install nlp==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import nlp\n",
    "from transformers import AutoTokenizer\n",
    "import dataclasses\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers.training_args import is_tpu_available\n",
    "from transformers.trainer import get_tpu_sampler\n",
    "from transformers.data.data_collator import DataCollator, InputDataClass\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from typing import List, Union, Dict\n",
    "from time import time\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    \"cola\": nlp.load_dataset('glue', name=\"cola\"),\n",
    "    \"stsb\": nlp.load_dataset('glue', name=\"stsb\"),\n",
    "#     \"qnli\": nlp.load_dataset('glue', name=\"qnli\"),\n",
    "    \"wnli\": nlp.load_dataset('glue', name=\"wnli\")\n",
    "    #\"mnli\": nlp.load_dataset('glue', name=\"mnli\")    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name, dataset in dataset_dict.items():\n",
    "    print(task_name)\n",
    "    print(dataset_dict[task_name][\"train\"][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskModel(transformers.PreTrainedModel):\n",
    "    def __init__(self, encoder, taskmodels_dict):\n",
    "        \"\"\"\n",
    "        Setting MultitaskModel up as a PretrainedModel allows us\n",
    "        to take better advantage of Trainer features\n",
    "        \"\"\"\n",
    "        super().__init__(transformers.PretrainedConfig())\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.taskmodels_dict = nn.ModuleDict(taskmodels_dict)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, model_name, model_type_dict, model_config_dict=None):\n",
    "        \"\"\"\n",
    "        This creates a MultitaskModel using the model class and config objects\n",
    "        from single-task models. \n",
    "\n",
    "        We do this by creating each single-task model, and having them share\n",
    "        the same encoder transformer.\n",
    "        \"\"\"\n",
    "        shared_encoder = None\n",
    "        taskmodels_dict = {}\n",
    "        for task_name, model_type in model_type_dict.items():\n",
    "            model = model_type.from_pretrained(\n",
    "                model_name, \n",
    "                config=model_config_dict[task_name],\n",
    "            )\n",
    "            if shared_encoder is None:\n",
    "                print('*****************')\n",
    "                #print(cls.get_encoder_attr_name(model))\n",
    "                \n",
    "                shared_encoder = getattr(model, model.base_model_prefix)\n",
    "                #shared_encoder\n",
    "                print(shared_encoder)\n",
    "                print('*****************')\n",
    "            else:\n",
    "                setattr(model, model.base_model_prefix\n",
    "                        , shared_encoder)\n",
    "            taskmodels_dict[task_name] = model\n",
    "        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\n",
    "\n",
    "\n",
    "    def forward(self, task_name, **kwargs):\n",
    "        return self.taskmodels_dict[task_name](**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************\n",
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "multitask_model = MultitaskModel.create(\n",
    "    model_name=model_name,\n",
    "    model_type_dict={\n",
    "        \"stsb\": transformers.AutoModelForSequenceClassification,\n",
    "        \"cola\": transformers.AutoModelForSequenceClassification,\n",
    "        \"wnli\": transformers.AutoModelForSequenceClassification,\n",
    "        #\"mnli\": transformers.AutoModelForSequenceClassification,\n",
    "    },\n",
    "    model_config_dict={\n",
    "        \"stsb\": transformers.AutoConfig.from_pretrained(model_name, num_labels=1),\n",
    "        \"cola\": transformers.AutoConfig.from_pretrained(model_name, num_labels=2),\n",
    "        \"wnli\": transformers.AutoConfig.from_pretrained(model_name, num_labels=2),\n",
    "        #\"mnli\": transformers.AutoConfig.from_pretrained(model_name, num_labels=3)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 340\n",
    "\n",
    "# def convert_to_sst2_features(example_batch):\n",
    "#     inputs = list(zip(example_batch['sentence']))\n",
    "#     features = tokenizer.batch_encode_plus(\n",
    "#         inputs,\n",
    "#         max_length=max_length,\n",
    "#         pad_to_max_length=True\n",
    "#     )\n",
    "    \n",
    "#     features['labels'] = example_batch['label']\n",
    "#     return features\n",
    "\n",
    "def convert_to_cola_features(example_batch):\n",
    "    #print(example_batch)\n",
    "    inputs = example_batch['sentence']\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "        inputs, max_length=max_length, pad_to_max_length=True\n",
    "    )\n",
    "    features[\"labels\"] = example_batch[\"label\"]\n",
    "    return features\n",
    "\n",
    "def convert_to_qnli_features(example_batch):\n",
    "    #print(example_batch)\n",
    "    inputs = list(zip(example_batch['question'], example_batch['sentence']))\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "        inputs, max_length=max_length, pad_to_max_length=True\n",
    "    )\n",
    "    features[\"labels\"] = example_batch[\"label\"]\n",
    "    return features\n",
    "\n",
    "def convert_to_wnli_features(example_batch):\n",
    "    #print(example_batch)\n",
    "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "        inputs, max_length=max_length, pad_to_max_length=True\n",
    "    )\n",
    "    features[\"labels\"] = example_batch[\"label\"]\n",
    "    return features\n",
    "\n",
    "def convert_to_mnli_features(example_batch):\n",
    "    #print(example_batch)\n",
    "    inputs = list(zip(example_batch['premise'], example_batch['hypothesis']))\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "        inputs, max_length=max_length, pad_to_max_length=True\n",
    "    )\n",
    "    features[\"labels\"] = example_batch[\"label\"]\n",
    "    return features\n",
    "\n",
    "def convert_to_stsb_features(example_batch):\n",
    "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "        inputs, max_length=max_length, pad_to_max_length=True\n",
    "    )\n",
    "    features[\"labels\"] = example_batch[\"label\"]\n",
    "    return features\n",
    "\n",
    "def convert_to_rte_features(example_batch):\n",
    "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "        inputs, max_length=max_length, pad_to_max_length=True\n",
    "    )\n",
    "    features[\"labels\"] = example_batch[\"label\"]\n",
    "    return features\n",
    "\n",
    "def convert_to_commonsense_qa_features(example_batch):\n",
    "    num_examples = len(example_batch[\"question\"])\n",
    "    num_choices = len(example_batch[\"choices\"][0][\"text\"])\n",
    "    features = {}\n",
    "    for example_i in range(num_examples):\n",
    "        choices_inputs = tokenizer.batch_encode_plus(\n",
    "            list(zip(\n",
    "                [example_batch[\"question\"][example_i]] * num_choices,\n",
    "                example_batch[\"choices\"][example_i][\"text\"],\n",
    "            )),\n",
    "            max_length=max_length, pad_to_max_length=True,\n",
    "        )\n",
    "        for k, v in choices_inputs.items():\n",
    "            if k not in features:\n",
    "                features[k] = []\n",
    "            features[k].append(v)\n",
    "    labels2id = {char: i for i, char in enumerate(\"ABCDE\")}\n",
    "    # Dummy answers for test\n",
    "    if example_batch[\"answerKey\"][0]:\n",
    "        features[\"labels\"] = [labels2id[ans] for ans in example_batch[\"answerKey\"]]\n",
    "    else:\n",
    "        features[\"labels\"] = [0] * num_examples    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_func_dict = {\n",
    "    \"stsb\": convert_to_stsb_features,\n",
    "    \"cola\": convert_to_cola_features,\n",
    "    \"wnli\": convert_to_wnli_features\n",
    "    #\"mnli\": convert_to_mnli_features,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.18it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cola train 8551 8551\n",
      "cola train 8551 8551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.62it/s]\n",
      " 50%|█████     | 1/2 [00:00<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cola validation 1043 1043\n",
      "cola validation 1043 1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.72it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cola test 1063 1063\n",
      "cola test 1063 1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.74it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stsb train 5749 5749\n",
      "stsb train 5749 5749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.23it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stsb validation 1500 1500\n",
      "stsb validation 1500 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stsb test 1379 1379\n",
      "stsb test 1379 1379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wnli train 635 635\n",
      "wnli train 635 635\n",
      "wnli validation 71 71\n",
      "wnli validation 71 71\n",
      "wnli test 146 146\n",
      "wnli test 146 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased',do_lower_case=False)\n",
    "columns_dict = {\n",
    "    \"stsb\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    \"cola\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    \"wnli\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    #\"mnli\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    \n",
    "}\n",
    "\n",
    "features_dict = {}\n",
    "for task_name, dataset in dataset_dict.items():\n",
    "    features_dict[task_name] = {}\n",
    "    for phase, phase_dataset in dataset.items():\n",
    "        features_dict[task_name][phase] = phase_dataset.map(\n",
    "            convert_func_dict[task_name],\n",
    "            batched=True,\n",
    "            load_from_cache_file=False,\n",
    "        )\n",
    "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))\n",
    "        features_dict[task_name][phase].set_format(\n",
    "            type=\"torch\", \n",
    "            columns=columns_dict[task_name],\n",
    "        )\n",
    "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPDataCollator(DataCollator):\n",
    "    \"\"\"\n",
    "    Extending the existing DataCollator to work with NLP dataset batches\n",
    "    \"\"\"\n",
    "    def collate_batch(self, features: List[Union[InputDataClass, Dict]]) -> Dict[str, torch.Tensor]:\n",
    "        first = features[0]\n",
    "        if isinstance(first, dict):\n",
    "          # NLP data sets current works presents features as lists of dictionary\n",
    "          # (one per example), so we  will adapt the collate_batch logic for that\n",
    "            if \"labels\" in first and first[\"labels\"] is not None:\n",
    "                if first[\"labels\"].dtype == torch.int64:\n",
    "                    labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n",
    "                else:\n",
    "                    labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.float)\n",
    "                batch = {\"labels\": labels}\n",
    "            for k, v in first.items():\n",
    "                if k != \"labels\" and v is not None and not isinstance(v, str):\n",
    "                    batch[k] = torch.stack([f[k] for f in features])\n",
    "            return batch\n",
    "        else:\n",
    "          # otherwise, revert to using the default collate_batch\n",
    "          return DefaultDataCollator().collate_batch(features)\n",
    "\n",
    "\n",
    "class StrIgnoreDevice(str):\n",
    "    \"\"\"\n",
    "    This is a hack. The Trainer is going call .to(device) on every input\n",
    "    value, but we need to pass in an additional `task_name` string.\n",
    "    This prevents it from throwing an error\n",
    "    \"\"\"\n",
    "    def to(self, device):\n",
    "        return self\n",
    "\n",
    "\n",
    "class DataLoaderWithTaskname:\n",
    "    \"\"\"\n",
    "    Wrapper around a DataLoader to also yield a task name\n",
    "    \"\"\"\n",
    "    def __init__(self, task_name, data_loader):\n",
    "        self.task_name = task_name\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "        self.batch_size = data_loader.batch_size\n",
    "        self.dataset = data_loader.dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.data_loader:\n",
    "            batch[\"task_name\"] = StrIgnoreDevice(self.task_name)\n",
    "            yield batch\n",
    "\n",
    "\n",
    "class MultitaskDataloader:\n",
    "    \"\"\"\n",
    "    Data loader that combines and samples from multiple single-task\n",
    "    data loaders.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader_dict):\n",
    "        self.dataloader_dict = dataloader_dict\n",
    "        self.num_batches_dict = {\n",
    "            task_name: len(dataloader) \n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "        self.task_name_list = list(self.dataloader_dict)\n",
    "        self.dataset = [None] * sum(\n",
    "            len(dataloader.dataset) \n",
    "            for dataloader in self.dataloader_dict.values()\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.num_batches_dict.values())\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        For each batch, sample a task, and yield a batch from the respective\n",
    "        task Dataloader.\n",
    "\n",
    "        We use size-proportional sampling, but you could easily modify this\n",
    "        to sample from some-other distribution.\n",
    "        \"\"\"\n",
    "        task_choice_list = []\n",
    "        for i, task_name in enumerate(self.task_name_list):\n",
    "            task_choice_list += [i] * self.num_batches_dict[task_name]\n",
    "        task_choice_list = np.array(task_choice_list)\n",
    "        np.random.shuffle(task_choice_list)\n",
    "        dataloader_iter_dict = {\n",
    "            task_name: iter(dataloader) \n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "        for task_choice in task_choice_list:\n",
    "            task_name = self.task_name_list[task_choice]\n",
    "            yield next(dataloader_iter_dict[task_name])    \n",
    "\n",
    "class MultitaskTrainer(transformers.Trainer):\n",
    "\n",
    "    def get_single_train_dataloader(self, task_name, train_dataset):\n",
    "        \"\"\"\n",
    "        Create a single-task data loader that also yields task names\n",
    "        \"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "        if is_tpu_available():\n",
    "            train_sampler = get_tpu_sampler(train_dataset)\n",
    "        else:\n",
    "            train_sampler = (\n",
    "                RandomSampler(train_dataset)\n",
    "                if self.args.local_rank == -1\n",
    "                else DistributedSampler(train_dataset)\n",
    "            )\n",
    "\n",
    "        data_loader = DataLoaderWithTaskname(\n",
    "            task_name=task_name,\n",
    "            data_loader=DataLoader(\n",
    "              train_dataset,\n",
    "              batch_size=self.args.train_batch_size,\n",
    "              sampler=train_sampler,\n",
    "              collate_fn=self.data_collator.collate_batch,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if is_tpu_available():\n",
    "            data_loader = pl.ParallelLoader(\n",
    "                data_loader, [self.args.device]\n",
    "            ).per_device_loader(self.args.device)\n",
    "        return data_loader\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns a MultitaskDataloader, which is not actually a Dataloader\n",
    "        but an iterable that returns a generator that samples from each \n",
    "        task Dataloader\n",
    "        \"\"\"\n",
    "        return MultitaskDataloader({\n",
    "            task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
    "            for task_name, task_dataset in self.train_dataset.items()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at  1608178710.4154248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e22ced9c9a140ab83caa82f663778ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecd995d484a4f51b77cccf6630e8081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1868.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 1.534033979922533, \"learning_rate\": 4.9107780157030696e-05, \"epoch\": 0.05353319057815846, \"step\": 100}\n",
      "{\"loss\": 1.138928828984499, \"learning_rate\": 4.821556031406139e-05, \"epoch\": 0.10706638115631692, \"step\": 200}\n",
      "{\"loss\": 0.8458010891079902, \"learning_rate\": 4.732334047109208e-05, \"epoch\": 0.16059957173447537, \"step\": 300}\n",
      "{\"loss\": 0.8967944318056107, \"learning_rate\": 4.643112062812277e-05, \"epoch\": 0.21413276231263384, \"step\": 400}\n",
      "{\"loss\": 0.8474469895660878, \"learning_rate\": 4.553890078515346e-05, \"epoch\": 0.2676659528907923, \"step\": 500}\n",
      "{\"loss\": 0.8665631264448166, \"learning_rate\": 4.4646680942184155e-05, \"epoch\": 0.32119914346895073, \"step\": 600}\n",
      "{\"loss\": 0.7265155212581158, \"learning_rate\": 4.375446109921485e-05, \"epoch\": 0.3747323340471092, \"step\": 700}\n",
      "{\"loss\": 0.7698795759677887, \"learning_rate\": 4.286224125624554e-05, \"epoch\": 0.4282655246252677, \"step\": 800}\n",
      "{\"loss\": 0.7649577705562115, \"learning_rate\": 4.1970021413276235e-05, \"epoch\": 0.4817987152034261, \"step\": 900}\n",
      "{\"loss\": 0.7408528414368629, \"learning_rate\": 4.107780157030692e-05, \"epoch\": 0.5353319057815846, \"step\": 1000}\n",
      "{\"loss\": 0.6986953417956829, \"learning_rate\": 4.0185581727337615e-05, \"epoch\": 0.588865096359743, \"step\": 1100}\n",
      "{\"loss\": 0.6671337549388409, \"learning_rate\": 3.9293361884368315e-05, \"epoch\": 0.6423982869379015, \"step\": 1200}\n",
      "{\"loss\": 0.6805687525868416, \"learning_rate\": 3.8401142041399e-05, \"epoch\": 0.69593147751606, \"step\": 1300}\n",
      "{\"loss\": 0.7100130595266819, \"learning_rate\": 3.7508922198429695e-05, \"epoch\": 0.7494646680942184, \"step\": 1400}\n",
      "{\"loss\": 0.7371896018832922, \"learning_rate\": 3.661670235546039e-05, \"epoch\": 0.8029978586723768, \"step\": 1500}\n",
      "{\"loss\": 0.6880168859660626, \"learning_rate\": 3.572448251249108e-05, \"epoch\": 0.8565310492505354, \"step\": 1600}\n",
      "{\"loss\": 0.7210544295608997, \"learning_rate\": 3.483226266952177e-05, \"epoch\": 0.9100642398286938, \"step\": 1700}\n",
      "{\"loss\": 0.6104093017056584, \"learning_rate\": 3.394004282655247e-05, \"epoch\": 0.9635974304068522, \"step\": 1800}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbe8610bc1a416294b9aa5327ac2d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1868.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.5431072661280631, \"learning_rate\": 3.3047822983583155e-05, \"epoch\": 1.0171306209850106, \"step\": 1900}\n",
      "{\"loss\": 0.4937980341725051, \"learning_rate\": 3.215560314061385e-05, \"epoch\": 1.0706638115631693, \"step\": 2000}\n",
      "{\"loss\": 0.4528332656994462, \"learning_rate\": 3.126338329764454e-05, \"epoch\": 1.1241970021413277, \"step\": 2100}\n",
      "{\"loss\": 0.4278562973998487, \"learning_rate\": 3.0371163454675235e-05, \"epoch\": 1.177730192719486, \"step\": 2200}\n",
      "{\"loss\": 0.4323692122101784, \"learning_rate\": 2.9478943611705928e-05, \"epoch\": 1.2312633832976445, \"step\": 2300}\n",
      "{\"loss\": 0.4581507395673543, \"learning_rate\": 2.8586723768736618e-05, \"epoch\": 1.284796573875803, \"step\": 2400}\n",
      "{\"loss\": 0.42963651043362916, \"learning_rate\": 2.769450392576731e-05, \"epoch\": 1.3383297644539613, \"step\": 2500}\n",
      "{\"loss\": 0.45649848332628606, \"learning_rate\": 2.6802284082798e-05, \"epoch\": 1.39186295503212, \"step\": 2600}\n",
      "{\"loss\": 0.4699536261707544, \"learning_rate\": 2.5910064239828698e-05, \"epoch\": 1.4453961456102784, \"step\": 2700}\n",
      "{\"loss\": 0.47400057593360545, \"learning_rate\": 2.5017844396859384e-05, \"epoch\": 1.4989293361884368, \"step\": 2800}\n",
      "{\"loss\": 0.4287833786569536, \"learning_rate\": 2.412562455389008e-05, \"epoch\": 1.5524625267665952, \"step\": 2900}\n",
      "{\"loss\": 0.47115230187773705, \"learning_rate\": 2.323340471092077e-05, \"epoch\": 1.6059957173447539, \"step\": 3000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/anaconda3/envs/mtxln-pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.40913829740136864, \"learning_rate\": 2.2341184867951464e-05, \"epoch\": 1.6595289079229123, \"step\": 3100}\n",
      "{\"loss\": 0.4401936921104789, \"learning_rate\": 2.1448965024982158e-05, \"epoch\": 1.7130620985010707, \"step\": 3200}\n",
      "{\"loss\": 0.4513427553512156, \"learning_rate\": 2.0556745182012848e-05, \"epoch\": 1.7665952890792291, \"step\": 3300}\n",
      "{\"loss\": 0.4185695594362915, \"learning_rate\": 1.966452533904354e-05, \"epoch\": 1.8201284796573876, \"step\": 3400}\n",
      "{\"loss\": 0.4556513046566397, \"learning_rate\": 1.8772305496074234e-05, \"epoch\": 1.873661670235546, \"step\": 3500}\n",
      "{\"loss\": 0.4320819187629968, \"learning_rate\": 1.7880085653104924e-05, \"epoch\": 1.9271948608137044, \"step\": 3600}\n",
      "{\"loss\": 0.38856534026563166, \"learning_rate\": 1.6987865810135617e-05, \"epoch\": 1.9807280513918628, \"step\": 3700}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628d3a5e31454ba09d57cad014d8bcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1868.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.3449959940928966, \"learning_rate\": 1.609564596716631e-05, \"epoch\": 2.0342612419700212, \"step\": 3800}\n",
      "{\"loss\": 0.2619784353300929, \"learning_rate\": 1.5203426124197004e-05, \"epoch\": 2.08779443254818, \"step\": 3900}\n",
      "{\"loss\": 0.26835629214998336, \"learning_rate\": 1.4311206281227696e-05, \"epoch\": 2.1413276231263385, \"step\": 4000}\n",
      "{\"loss\": 0.24683412973303348, \"learning_rate\": 1.3418986438258387e-05, \"epoch\": 2.194860813704497, \"step\": 4100}\n",
      "{\"loss\": 0.247724237262737, \"learning_rate\": 1.252676659528908e-05, \"epoch\": 2.2483940042826553, \"step\": 4200}\n",
      "{\"loss\": 0.24813799444586038, \"learning_rate\": 1.1634546752319772e-05, \"epoch\": 2.3019271948608138, \"step\": 4300}\n",
      "{\"loss\": 0.25699892740696667, \"learning_rate\": 1.0742326909350464e-05, \"epoch\": 2.355460385438972, \"step\": 4400}\n",
      "{\"loss\": 0.26233643759973346, \"learning_rate\": 9.850107066381155e-06, \"epoch\": 2.4089935760171306, \"step\": 4500}\n",
      "{\"loss\": 0.24313153212191538, \"learning_rate\": 8.95788722341185e-06, \"epoch\": 2.462526766595289, \"step\": 4600}\n",
      "{\"loss\": 0.22512058345833794, \"learning_rate\": 8.065667380442542e-06, \"epoch\": 2.5160599571734474, \"step\": 4700}\n",
      "{\"loss\": 0.25313066456699745, \"learning_rate\": 7.173447537473234e-06, \"epoch\": 2.569593147751606, \"step\": 4800}\n",
      "{\"loss\": 0.2558599184313789, \"learning_rate\": 6.281227694503926e-06, \"epoch\": 2.6231263383297643, \"step\": 4900}\n",
      "{\"loss\": 0.2641851124726236, \"learning_rate\": 5.389007851534619e-06, \"epoch\": 2.6766595289079227, \"step\": 5000}\n",
      "{\"loss\": 0.266137686050497, \"learning_rate\": 4.496788008565311e-06, \"epoch\": 2.730192719486081, \"step\": 5100}\n",
      "{\"loss\": 0.26639488752232865, \"learning_rate\": 3.6045681655960027e-06, \"epoch\": 2.78372591006424, \"step\": 5200}\n",
      "{\"loss\": 0.22807481056079268, \"learning_rate\": 2.7123483226266955e-06, \"epoch\": 2.8372591006423984, \"step\": 5300}\n",
      "{\"loss\": 0.25232252353569495, \"learning_rate\": 1.8201284796573876e-06, \"epoch\": 2.890792291220557, \"step\": 5400}\n",
      "{\"loss\": 0.2112305288016796, \"learning_rate\": 9.279086366880799e-07, \"epoch\": 2.9443254817987152, \"step\": 5500}\n",
      "{\"loss\": 0.2013189473422244, \"learning_rate\": 3.5688793718772306e-08, \"epoch\": 2.9978586723768736, \"step\": 5600}\n",
      "\n",
      "\n",
      "1138.8422915935516\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "print('Training started at ',start)\n",
    "train_dataset = {\n",
    "    task_name: dataset[\"train\"] \n",
    "    for task_name, dataset in features_dict.items()\n",
    "}\n",
    "trainer = MultitaskTrainer(\n",
    "    model=multitask_model,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=\"./models/bert_multitask\",\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=5e-5,\n",
    "        do_train=True,\n",
    "        num_train_epochs=3,\n",
    "        # Adjust batch size if this doesn't fit on the Colab GPU\n",
    "        per_device_train_batch_size=8,  \n",
    "        save_steps=3000,\n",
    "        logging_steps=100,\n",
    "        logging_dir='bert_logs'\n",
    "    ),\n",
    "    data_collator=NLPDataCollator(),\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "trainer.train()\n",
    "print(time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import time\n",
    "# start=time()\n",
    "# print('Training started at ',start)\n",
    "# train_dataset = {\n",
    "#     task_name: dataset[\"train\"] \n",
    "#     for task_name, dataset in features_dict.items()\n",
    "# }\n",
    "# trainer = MultitaskTrainer(\n",
    "#     model=multitask_model,\n",
    "#     args=transformers.TrainingArguments(\n",
    "#         output_dir=\"./models/multitask_model\",\n",
    "#         overwrite_output_dir=True,\n",
    "#         learning_rate=5e-5,\n",
    "#         do_train=True,\n",
    "#         num_train_epochs=3,\n",
    "#         # Adjust batch size if this doesn't fit on the Colab GPU\n",
    "#         per_device_train_batch_size=32,  \n",
    "#         save_steps=3000,\n",
    "#     ),\n",
    "#     data_collator=NLPDataCollator(),\n",
    "#     train_dataset=train_dataset,\n",
    "# )\n",
    "# trainer.train(optimizer='adamax')\n",
    "# print(time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((time()-start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7f50a6076310>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dabf4f292d649ed94e5ee4111dbbb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: cola', max=131.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7f50a6076310>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c37e0592f5248cf91dc89bc2ed89c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: stsb', max=188.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7f50a6076310>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6dc35898a24096a527eb54c448591d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: wnli', max=9.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds_dict = {}\n",
    "for task_name in [\"cola\", \"stsb\", \"wnli\"]:\n",
    "    eval_dataloader = DataLoaderWithTaskname(\n",
    "        task_name,\n",
    "        trainer.get_eval_dataloader(eval_dataset=features_dict[task_name][\"validation\"])\n",
    "    )\n",
    "    print(eval_dataloader.data_loader.collate_fn)\n",
    "    preds_dict[task_name] = trainer._prediction_loop(\n",
    "        eval_dataloader, \n",
    "        description=f\"Validation: {task_name}\",\n",
    "    )\n",
    "    #print(task_name,preds_dict[task_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scipy sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute RTE\n",
    "# nlp.load_metric('glue', name=\"cola\").compute(\n",
    "#     np.argmax(preds_dict[\"cola\"].predictions, axis=1),\n",
    "#     preds_dict[\"cola\"].label_ids,\n",
    "# )\n",
    "\n",
    "cola_metric=nlp.load_metric('glue', name='cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.argmax(preds_dict[\"cola\"].predictions, axis=1) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.load_metric('glue', name=\"stsb\").compute(\n",
    "    preds_dict[\"stsb\"].predictions.flatten(),\n",
    "    preds_dict[\"stsb\"].label_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict[\"cola\"].label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute Commonsense QA\n",
    "np.mean(\n",
    "    np.argmax(preds_dict[\"wnli\"].predictions, axis=1)\n",
    "    == preds_dict[\"wnli\"].label_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "scores['cola'] = nlp.load_metric('glue', name='cola').compute(\n",
    "    np.argmax(preds_dict['cola'].predictions, axis=1),\n",
    "    preds_dict['cola'].label_ids\n",
    ")\n",
    "scores['stsb'] = nlp.load_metric('glue', name=\"stsb\").compute(\n",
    "    preds_dict[\"stsb\"].predictions.flatten(),\n",
    "    preds_dict[\"stsb\"].label_ids,\n",
    ")\n",
    "scores['wnli'] = nlp.load_metric('glue', name='wnli').compute(\n",
    "    np.argmax(preds_dict['wnli'].predictions, axis=1),\n",
    "    preds_dict['wnli'].label_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cola': {'matthews_correlation': 0.5208447598175431},\n",
       " 'stsb': {'pearson': 0.8678433501501895, 'spearmanr': 0.8655824809199388},\n",
       " 'wnli': {'accuracy': 0.4507042253521127}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('bert_scores.pkl', 'wb') as fd :\n",
    "    pickle.dump(scores, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
