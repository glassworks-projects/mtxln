{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import nlp\n",
    "from transformers import AutoTokenizer\n",
    "import dataclasses\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers.training_args import is_tpu_available\n",
    "from transformers.trainer import get_tpu_sampler\n",
    "from transformers.data.data_collator import DataCollator, InputDataClass\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from typing import List, Union, Dict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "\n",
    "TASKS = ['rte', 'wnli']\n",
    "\n",
    "# modify this if you're encountering memory errors with your hardware setup\n",
    "max_length = 340\n",
    "\n",
    "# to run with BERT, swap the commented and uncommented lines below for model_class\n",
    "# model_class = 'bert'\n",
    "model_class = 'xlnet'\n",
    "model_name = '%s-base-cased' % model_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {task : nlp.load_dataset('glue', name=task) for task in TASKS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskModel(transformers.PreTrainedModel):\n",
    "    def __init__(self, encoder, taskmodels_dict):\n",
    "        \"\"\"\n",
    "        Setting MultitaskModel up as a PretrainedModel allows us\n",
    "        to take better advantage of Trainer features\n",
    "        \"\"\"\n",
    "        super().__init__(transformers.PretrainedConfig(max_length=max_length))\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.taskmodels_dict = nn.ModuleDict(taskmodels_dict)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, model_name, model_type_dict, model_config_dict=None):\n",
    "        \"\"\"\n",
    "        This creates a MultitaskModel using the model class and config objects\n",
    "        from single-task models. \n",
    "\n",
    "        We do this by creating each single-task model, and having them share\n",
    "        the same encoder transformer.\n",
    "        \"\"\"\n",
    "        shared_encoder = None\n",
    "        taskmodels_dict = {}\n",
    "        for task_name, model_type in model_type_dict.items():\n",
    "            model = model_type.from_pretrained(\n",
    "                model_name, \n",
    "                config=model_config_dict[task_name],\n",
    "            )\n",
    "            if shared_encoder is None:\n",
    "                shared_encoder = getattr(model, model.base_model_prefix)                \n",
    "            else:\n",
    "                setattr(model, model.base_model_prefix\n",
    "                        , shared_encoder)\n",
    "            taskmodels_dict[task_name] = model\n",
    "        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\n",
    "\n",
    "\n",
    "    def forward(self, task_name, **kwargs):\n",
    "        return self.taskmodels_dict[task_name](**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wnli_features(example_batch):\n",
    "    #print(example_batch)\n",
    "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "        inputs, max_length=max_length, pad_to_max_length=True\n",
    "    )\n",
    "    features[\"labels\"] = example_batch[\"label\"]\n",
    "    return features\n",
    "\n",
    "def convert_to_rte_features(example_batch):\n",
    "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n",
    "    features = tokenizer.batch_encode_plus(\n",
    "        inputs, max_length=max_length, pad_to_max_length=True\n",
    "    )\n",
    "    features[\"labels\"] = example_batch[\"label\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPDataCollator(DataCollator):\n",
    "    \"\"\"\n",
    "    Extending the existing DataCollator to work with NLP dataset batches\n",
    "    \"\"\"\n",
    "    def collate_batch(self, features: List[Union[InputDataClass, Dict]]) -> Dict[str, torch.Tensor]:\n",
    "        first = features[0]\n",
    "        if isinstance(first, dict):\n",
    "          # NLP data sets current works presents features as lists of dictionary\n",
    "          # (one per example), so we  will adapt the collate_batch logic for that\n",
    "            if \"labels\" in first and first[\"labels\"] is not None:\n",
    "                if first[\"labels\"].dtype == torch.int64:\n",
    "                    labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n",
    "                else:\n",
    "                    labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.float)\n",
    "                batch = {\"labels\": labels}\n",
    "            for k, v in first.items():\n",
    "                if k != \"labels\" and v is not None and not isinstance(v, str):\n",
    "                    batch[k] = torch.stack([f[k] for f in features])\n",
    "            return batch\n",
    "        else:\n",
    "          # otherwise, revert to using the default collate_batch\n",
    "          return DefaultDataCollator().collate_batch(features)\n",
    "\n",
    "\n",
    "class StrIgnoreDevice(str):\n",
    "    \"\"\"\n",
    "    This is a hack. The Trainer is going call .to(device) on every input\n",
    "    value, but we need to pass in an additional `task_name` string.\n",
    "    This prevents it from throwing an error\n",
    "    \"\"\"\n",
    "    def to(self, device):\n",
    "        return self\n",
    "\n",
    "\n",
    "class DataLoaderWithTaskname:\n",
    "    \"\"\"\n",
    "    Wrapper around a DataLoader to also yield a task name\n",
    "    \"\"\"\n",
    "    def __init__(self, task_name, data_loader):\n",
    "        self.task_name = task_name\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "        self.batch_size = data_loader.batch_size\n",
    "        self.dataset = data_loader.dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.data_loader:\n",
    "            batch[\"task_name\"] = StrIgnoreDevice(self.task_name)\n",
    "            yield batch\n",
    "\n",
    "\n",
    "class MultitaskDataloader:\n",
    "    \"\"\"\n",
    "    Data loader that combines and samples from multiple single-task\n",
    "    data loaders.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader_dict):\n",
    "        self.dataloader_dict = dataloader_dict\n",
    "        self.num_batches_dict = {\n",
    "            task_name: len(dataloader) \n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "        self.task_name_list = list(self.dataloader_dict)\n",
    "        self.dataset = [None] * sum(\n",
    "            len(dataloader.dataset) \n",
    "            for dataloader in self.dataloader_dict.values()\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.num_batches_dict.values())\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        For each batch, sample a task, and yield a batch from the respective\n",
    "        task Dataloader.\n",
    "\n",
    "        We use size-proportional sampling, but you could easily modify this\n",
    "        to sample from some-other distribution.\n",
    "        \"\"\"\n",
    "        task_choice_list = []\n",
    "        for i, task_name in enumerate(self.task_name_list):\n",
    "            task_choice_list += [i] * self.num_batches_dict[task_name]\n",
    "        task_choice_list = np.array(task_choice_list)\n",
    "        np.random.shuffle(task_choice_list)\n",
    "        dataloader_iter_dict = {\n",
    "            task_name: iter(dataloader) \n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "        for task_choice in task_choice_list:\n",
    "            task_name = self.task_name_list[task_choice]\n",
    "            yield next(dataloader_iter_dict[task_name])    \n",
    "\n",
    "class MultitaskTrainer(transformers.Trainer):\n",
    "\n",
    "    def get_single_train_dataloader(self, task_name, train_dataset):\n",
    "        \"\"\"\n",
    "        Create a single-task data loader that also yields task names\n",
    "        \"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "        if is_tpu_available():\n",
    "            train_sampler = get_tpu_sampler(train_dataset)\n",
    "        else:\n",
    "            train_sampler = (\n",
    "                RandomSampler(train_dataset)\n",
    "                if self.args.local_rank == -1\n",
    "                else DistributedSampler(train_dataset)\n",
    "            )\n",
    "\n",
    "        data_loader = DataLoaderWithTaskname(\n",
    "            task_name=task_name,\n",
    "            data_loader=DataLoader(\n",
    "              train_dataset,\n",
    "              batch_size=self.args.train_batch_size,\n",
    "              sampler=train_sampler,\n",
    "              collate_fn=self.data_collator.collate_batch,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if is_tpu_available():\n",
    "            data_loader = pl.ParallelLoader(\n",
    "                data_loader, [self.args.device]\n",
    "            ).per_device_loader(self.args.device)\n",
    "        return data_loader\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns a MultitaskDataloader, which is not actually a Dataloader\n",
    "        but an iterable that returns a generator that samples from each \n",
    "        task Dataloader\n",
    "        \"\"\"\n",
    "        return MultitaskDataloader({\n",
    "            task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
    "            for task_name, task_dataset in self.train_dataset.items()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_caller = locals()\n",
    "\n",
    "convert_func_dict = {task : local_caller['convert_to_%s_features' % task] for task in TASKS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/mtl_xlnet_model_3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3\n",
    "output_dir=\"./models/mtl_%s_model_%i\" % (model_class, i)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dc6e4e6041473bb3c378ca9fc66aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476d3ecbe14848b898b8f9f2deaeee71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd57ee87f16743c19807f4cdab8d04db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.11it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte train 2490 2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte validation 277 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte test 3000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wnli train 635 635\n",
      "wnli validation 71 71\n",
      "wnli test 146 146\n",
      "Training for max_length= 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96a9c0cd0b54bd681f7af1337495b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54819bc3a4a7449ba99211179cc1e8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.7186029779911042, \"learning_rate\": 4.5748299319727895e-05, \"epoch\": 0.25510204081632654, \"step\": 100}\n",
      "{\"loss\": 0.7053953933715821, \"learning_rate\": 4.149659863945579e-05, \"epoch\": 0.5102040816326531, \"step\": 200}\n",
      "{\"loss\": 0.7100035929679871, \"learning_rate\": 3.724489795918368e-05, \"epoch\": 0.7653061224489796, \"step\": 300}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8a85d5634b446faf53ae44aaa177dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.7043132102489471, \"learning_rate\": 3.2993197278911564e-05, \"epoch\": 1.0204081632653061, \"step\": 400}\n",
      "{\"loss\": 0.7134725701808929, \"learning_rate\": 2.8741496598639456e-05, \"epoch\": 1.2755102040816326, \"step\": 500}\n",
      "{\"loss\": 0.7078163838386535, \"learning_rate\": 2.448979591836735e-05, \"epoch\": 1.5306122448979593, \"step\": 600}\n",
      "{\"loss\": 0.7030082887411118, \"learning_rate\": 2.023809523809524e-05, \"epoch\": 1.7857142857142856, \"step\": 700}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2c2983ea6543e58af7327c6d15fbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.6986460644006729, \"learning_rate\": 1.5986394557823133e-05, \"epoch\": 2.0408163265306123, \"step\": 800}\n",
      "{\"loss\": 0.701382218003273, \"learning_rate\": 1.1734693877551021e-05, \"epoch\": 2.295918367346939, \"step\": 900}\n",
      "{\"loss\": 0.6982429444789886, \"learning_rate\": 7.482993197278912e-06, \"epoch\": 2.5510204081632653, \"step\": 1000}\n",
      "{\"loss\": 0.6986451315879821, \"learning_rate\": 3.231292517006803e-06, \"epoch\": 2.806122448979592, \"step\": 1100}\n",
      "\n",
      "\n",
      "Training time= 79.94278717041016\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea920bc520>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb449fa5574494c9c5d7876b8a2a37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: rte', max=35.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea920bc520>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bf091f92334f199abe14e3ea06f2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: wnli', max=9.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.12it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte train 2490 2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte validation 277 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte test 3000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wnli train 635 635\n",
      "wnli validation 71 71\n",
      "wnli test 146 146\n",
      "Training for max_length= 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c11124bcc24d1b841b5d6926b1792f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1f15f07e154f4f9965693d8549ace6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.7108332234621048, \"learning_rate\": 4.5748299319727895e-05, \"epoch\": 0.25510204081632654, \"step\": 100}\n",
      "{\"loss\": 0.7074322354793549, \"learning_rate\": 4.149659863945579e-05, \"epoch\": 0.5102040816326531, \"step\": 200}\n",
      "{\"loss\": 0.7087937253713608, \"learning_rate\": 3.724489795918368e-05, \"epoch\": 0.7653061224489796, \"step\": 300}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb6ce870e9d42908ad6fe8ec9c78b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.6963228005170822, \"learning_rate\": 3.2993197278911564e-05, \"epoch\": 1.0204081632653061, \"step\": 400}\n",
      "{\"loss\": 0.7029298794269562, \"learning_rate\": 2.8741496598639456e-05, \"epoch\": 1.2755102040816326, \"step\": 500}\n",
      "{\"loss\": 0.7071313148736954, \"learning_rate\": 2.448979591836735e-05, \"epoch\": 1.5306122448979593, \"step\": 600}\n",
      "{\"loss\": 0.7031861060857773, \"learning_rate\": 2.023809523809524e-05, \"epoch\": 1.7857142857142856, \"step\": 700}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267bd1496e00456b8e02d5a74e0f4360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.6953255981206894, \"learning_rate\": 1.5986394557823133e-05, \"epoch\": 2.0408163265306123, \"step\": 800}\n",
      "{\"loss\": 0.6647786656022072, \"learning_rate\": 1.1734693877551021e-05, \"epoch\": 2.295918367346939, \"step\": 900}\n",
      "{\"loss\": 0.6738974487781525, \"learning_rate\": 7.482993197278912e-06, \"epoch\": 2.5510204081632653, \"step\": 1000}\n",
      "{\"loss\": 0.639062225818634, \"learning_rate\": 3.231292517006803e-06, \"epoch\": 2.806122448979592, \"step\": 1100}\n",
      "\n",
      "\n",
      "Training time= 80.61690902709961\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea8f5e3910>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849c530b7f1b4757aa3e6fbe42afcdfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: rte', max=35.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea8f5e3910>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b29164c3544b1c83dc832cf57b097f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: wnli', max=9.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.12it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte train 2490 2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.43it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte validation 277 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte test 3000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wnli train 635 635\n",
      "wnli validation 71 71\n",
      "wnli test 146 146\n",
      "Training for max_length= 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f00f2c580b4b288a899e8536a453a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97b51f90c99406f888c1e5e4130b27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.715479696393013, \"learning_rate\": 4.5748299319727895e-05, \"epoch\": 0.25510204081632654, \"step\": 100}\n",
      "{\"loss\": 0.7195290058851243, \"learning_rate\": 4.149659863945579e-05, \"epoch\": 0.5102040816326531, \"step\": 200}\n",
      "{\"loss\": 0.7065274339914321, \"learning_rate\": 3.724489795918368e-05, \"epoch\": 0.7653061224489796, \"step\": 300}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaaf27b3e57e47fd956289effa1d7baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.7005174857378006, \"learning_rate\": 3.2993197278911564e-05, \"epoch\": 1.0204081632653061, \"step\": 400}\n",
      "{\"loss\": 0.7149336007237435, \"learning_rate\": 2.8741496598639456e-05, \"epoch\": 1.2755102040816326, \"step\": 500}\n",
      "{\"loss\": 0.7026018738746643, \"learning_rate\": 2.448979591836735e-05, \"epoch\": 1.5306122448979593, \"step\": 600}\n",
      "{\"loss\": 0.705677507519722, \"learning_rate\": 2.023809523809524e-05, \"epoch\": 1.7857142857142856, \"step\": 700}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a027ace1482e4b35a922bbbb83861f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.6895429331064225, \"learning_rate\": 1.5986394557823133e-05, \"epoch\": 2.0408163265306123, \"step\": 800}\n",
      "{\"loss\": 0.6852729201316834, \"learning_rate\": 1.1734693877551021e-05, \"epoch\": 2.295918367346939, \"step\": 900}\n",
      "{\"loss\": 0.6801022806763649, \"learning_rate\": 7.482993197278912e-06, \"epoch\": 2.5510204081632653, \"step\": 1000}\n",
      "{\"loss\": 0.6553061833977699, \"learning_rate\": 3.231292517006803e-06, \"epoch\": 2.806122448979592, \"step\": 1100}\n",
      "\n",
      "\n",
      "Training time= 79.02348065376282\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea8f58b220>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdad2ad0372e49a9a16530f42929907a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: rte', max=35.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea8f58b220>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758fb71b790c4472aec4906d98d2c323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: wnli', max=9.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte train 2490 2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte validation 277 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte test 3000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 23.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wnli train 635 635\n",
      "wnli validation 71 71\n",
      "wnli test 146 146\n",
      "Training for max_length= 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf56d0c928949608f9181289dfa08be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d14835510cc4255abafb125da794ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.7169240599870682, \"learning_rate\": 4.5748299319727895e-05, \"epoch\": 0.25510204081632654, \"step\": 100}\n",
      "{\"loss\": 0.7124525338411332, \"learning_rate\": 4.149659863945579e-05, \"epoch\": 0.5102040816326531, \"step\": 200}\n",
      "{\"loss\": 0.7098486286401748, \"learning_rate\": 3.724489795918368e-05, \"epoch\": 0.7653061224489796, \"step\": 300}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7774041aa542098dfce74be0b434e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.7003032457828522, \"learning_rate\": 3.2993197278911564e-05, \"epoch\": 1.0204081632653061, \"step\": 400}\n",
      "{\"loss\": 0.6978567108511925, \"learning_rate\": 2.8741496598639456e-05, \"epoch\": 1.2755102040816326, \"step\": 500}\n",
      "{\"loss\": 0.7017502546310425, \"learning_rate\": 2.448979591836735e-05, \"epoch\": 1.5306122448979593, \"step\": 600}\n",
      "{\"loss\": 0.7034722074866295, \"learning_rate\": 2.023809523809524e-05, \"epoch\": 1.7857142857142856, \"step\": 700}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fd0a1c3b3740e985d567b83564f959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.6754904577136039, \"learning_rate\": 1.5986394557823133e-05, \"epoch\": 2.0408163265306123, \"step\": 800}\n",
      "{\"loss\": 0.6081404575705528, \"learning_rate\": 1.1734693877551021e-05, \"epoch\": 2.295918367346939, \"step\": 900}\n",
      "{\"loss\": 0.6150469425320625, \"learning_rate\": 7.482993197278912e-06, \"epoch\": 2.5510204081632653, \"step\": 1000}\n",
      "{\"loss\": 0.5673000726103783, \"learning_rate\": 3.231292517006803e-06, \"epoch\": 2.806122448979592, \"step\": 1100}\n",
      "\n",
      "\n",
      "Training time= 88.88202261924744\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea85062f70>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910e35ecce6e4fee892fa51f82fa4a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: rte', max=35.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea85062f70>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7017975ab89749b4a4e352a4026266a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: wnli', max=9.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.12it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte train 2490 2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.43it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte validation 277 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rte test 3000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wnli train 635 635\n",
      "wnli validation 71 71\n",
      "wnli test 146 146\n",
      "Training for max_length= 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1231e22bce484930adbbe1be845af98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b730d9be9f943509001864ba3b174b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.7152904629707336, \"learning_rate\": 4.5748299319727895e-05, \"epoch\": 0.25510204081632654, \"step\": 100}\n",
      "{\"loss\": 0.7141690856218338, \"learning_rate\": 4.149659863945579e-05, \"epoch\": 0.5102040816326531, \"step\": 200}\n",
      "{\"loss\": 0.7016553252935409, \"learning_rate\": 3.724489795918368e-05, \"epoch\": 0.7653061224489796, \"step\": 300}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782a65b8df7f4099a8a35571f2676fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.6999205464124679, \"learning_rate\": 3.2993197278911564e-05, \"epoch\": 1.0204081632653061, \"step\": 400}\n",
      "{\"loss\": 0.7085598665475845, \"learning_rate\": 2.8741496598639456e-05, \"epoch\": 1.2755102040816326, \"step\": 500}\n",
      "{\"loss\": 0.7086043965816498, \"learning_rate\": 2.448979591836735e-05, \"epoch\": 1.5306122448979593, \"step\": 600}\n",
      "{\"loss\": 0.707070050239563, \"learning_rate\": 2.023809523809524e-05, \"epoch\": 1.7857142857142856, \"step\": 700}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289c466913b84bb79f0653e21f36bf1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=392.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.7035528546571732, \"learning_rate\": 1.5986394557823133e-05, \"epoch\": 2.0408163265306123, \"step\": 800}\n",
      "{\"loss\": 0.6993995487689972, \"learning_rate\": 1.1734693877551021e-05, \"epoch\": 2.295918367346939, \"step\": 900}\n",
      "{\"loss\": 0.7048195344209671, \"learning_rate\": 7.482993197278912e-06, \"epoch\": 2.5510204081632653, \"step\": 1000}\n",
      "{\"loss\": 0.7000831192731858, \"learning_rate\": 3.231292517006803e-06, \"epoch\": 2.806122448979592, \"step\": 1100}\n",
      "\n",
      "\n",
      "Training time= 117.56548547744751\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea8f59f820>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f27a6ad5ae40d2b3e8f15085a1142b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: rte', max=35.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7fea8f59f820>>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd19e2c4e32142528f599bb861246372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation: wnli', max=9.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "scores = {\n",
    "    'rte' : {},\n",
    "    'wnli': {}\n",
    "}\n",
    "\n",
    "# This will calculate for sequence length 8, 16, ..., 128\n",
    "# Adjust loop range to fit your experiment and hardware constraints \n",
    "for i in range(3,8):\n",
    "    max_length=2**i\n",
    "\n",
    "    multitask_model = MultitaskModel.create(\n",
    "        model_name=model_name,\n",
    "        model_type_dict={\n",
    "            \"rte\": transformers.AutoModelForSequenceClassification,\n",
    "            \"wnli\": transformers.AutoModelForSequenceClassification\n",
    "        },\n",
    "        model_config_dict={\n",
    "            \"rte\": transformers.AutoConfig.from_pretrained(model_name, num_labels=2)\n",
    "            \"wnli\": transformers.AutoConfig.from_pretrained(model_name, num_labels=2)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=True)\n",
    "    \n",
    "    columns_dict = {task : ['input_ids', 'attention_mask', 'labels'] for task in TASKS}\n",
    "\n",
    "    features_dict = {}\n",
    "    for task_name, dataset in dataset_dict.items():\n",
    "        features_dict[task_name] = {}\n",
    "        for phase, phase_dataset in dataset.items():\n",
    "            features_dict[task_name][phase] = phase_dataset.map(\n",
    "                convert_func_dict[task_name],\n",
    "                batched=True,\n",
    "                load_from_cache_file=False,\n",
    "            )\n",
    "            features_dict[task_name][phase].set_format(\n",
    "                type=\"torch\", \n",
    "                columns=columns_dict[task_name],\n",
    "            )\n",
    "            print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))\n",
    "            \n",
    "    train_dataset = {\n",
    "    task_name: dataset[\"train\"] \n",
    "    for task_name, dataset in features_dict.items()\n",
    "    }\n",
    "    trainer = MultitaskTrainer(\n",
    "        model=multitask_model,\n",
    "        args=transformers.TrainingArguments(\n",
    "            output_dir=\"./models/mtl_%s_model_%i\" % (model_class, i),\n",
    "            overwrite_output_dir=True,\n",
    "            learning_rate=5e-5,\n",
    "            do_train=True,\n",
    "            num_train_epochs=3,\n",
    "            # Adjust batch size if this doesn't fit on the Colab GPU\n",
    "            per_device_train_batch_size=8,  \n",
    "            save_steps=3000,\n",
    "            logging_steps=100,\n",
    "            logging_dir='./mtl_%s_logs_%i' % (model_class, i)\n",
    "        ),\n",
    "        data_collator=NLPDataCollator(),\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    print('Training for max_length=',2**i)\n",
    "    start=time()\n",
    "    trainer.train()\n",
    "    print('Training time=',time()-start)\n",
    "    preds_dict = {}\n",
    "    for task_name in TASKS:\n",
    "        eval_dataloader = DataLoaderWithTaskname(\n",
    "            task_name,\n",
    "            trainer.get_eval_dataloader(eval_dataset=features_dict[task_name][\"validation\"])\n",
    "        )\n",
    "        print(eval_dataloader.data_loader.collate_fn)\n",
    "        preds_dict[task_name] = trainer._prediction_loop(\n",
    "            eval_dataloader, \n",
    "            description=f\"Validation: {task_name}\",\n",
    "        )\n",
    "     \n",
    "    scores['rte'][i] = nlp.load_metric('glue', name=\"rte\").compute(\n",
    "        np.argmax(preds_dict[\"rte\"].predictions, axis=1),\n",
    "        preds_dict[\"rte\"].label_ids\n",
    "    )\n",
    "    \n",
    "    scores['wnli'][i] = nlp.load_metric('glue', name=\"wnli\").compute(\n",
    "        np.argmax(preds_dict[\"wnli\"].predictions, axis=1),\n",
    "        preds_dict[\"wnli\"].label_ids\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seq-length-%s.pkl' % model_class, 'wb') as file :\n",
    "    pickle.dump(scores, file)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
